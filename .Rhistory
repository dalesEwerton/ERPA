plot(modelo.knn)
plot(varImp(modelo.knn))
plot(varImp(modelo.knn))
varImp(modelo.knn)
knn.predict <- predict(modelo.knn, test_data)
test_data$pred <- knn.predict
View(test_data)
#library(keras)
#UNCOMMENT TO INSTALL KERAS
#install_keras(method = c("auto", "virtualenv", "conda"), conda = "auto",
#  tensorflow = "default", extra_packages = NULL)
library(caret)
set.seed(500)
#Defininindo o particionamento dos dados
partition <- createDataPartition(y=data$Nome_do_Candidato, p=.8, list=FALSE)
fit_data  <- data[partition,]
test_data <- data[-partition,]
ctrl <- trainControl(method = "cv", number = 5, search = "random")
grid <- expand.grid(k = 1:50)
modelo.knn <- train(
Resultado_Final ~.,
data       = data,
method     = "knn",
trControl  = ctrl,
preProcess = c('nzv'),
tuneGrid   = grid,
na.action  = na.omit
)
plot(modelo.knn)
knn.predict <- predict(modelo.knn, test_data)
test_data$pred <- knn.predict
ggplot(test_data, aes(x = knn.predict, y = Resultado_Final)) +
labs(title = "Modelo KNN - Obs vs Pred",
x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
#library(keras)
#UNCOMMENT TO INSTALL KERAS
#install_keras(method = c("auto", "virtualenv", "conda"), conda = "auto",
#  tensorflow = "default", extra_packages = NULL)
library(caret)
set.seed(500)
#Defininindo o particionamento dos dados
partition <- createDataPartition(y=data$Nome_do_Candidato, p=.8, list=FALSE)
fit_data  <- data[partition,]
test_data <- data[-partition,]
ctrl <- trainControl(method = "cv", number = 5, search = "random")
grid <- expand.grid(k = 30)
modelo.knn <- train(
Resultado_Final ~.,
data       = data,
method     = "knn",
trControl  = ctrl,
preProcess = c('nzv'),
tuneGrid   = grid,
na.action  = na.omit
)
plot(modelo.knn)
#library(keras)
#UNCOMMENT TO INSTALL KERAS
#install_keras(method = c("auto", "virtualenv", "conda"), conda = "auto",
#  tensorflow = "default", extra_packages = NULL)
library(caret)
set.seed(500)
#Defininindo o particionamento dos dados
partition <- createDataPartition(y=data$Nome_do_Candidato, p=.8, list=FALSE)
fit_data  <- data[partition,]
test_data <- data[-partition,]
ctrl <- trainControl(method = "cv", number = 5, search = "random")
grid <- expand.grid(k = 30)
modelo.knn <- train(
Resultado_Final ~.,
data       = data,
method     = "knn",
trControl  = ctrl,
preProcess = c('nzv'),
tuneGrid   = grid,
na.action  = na.omit
)
/plot(modelo.knn)
set.seed(500)
#Defininindo o particionamento dos dados
partition <- createDataPartition(y=data$Nome_do_Candidato, p=.8, list=FALSE)
fit_data  <- data[partition,]
test_data <- data[-partition,]
ctrl <- trainControl(method = "cv", number = 5, search = "random")
grid <- expand.grid(k = 30)
modelo.knn <- train(
Resultado_Final ~.,
data       = data,
method     = "knn",
trControl  = ctrl,
preProcess = c('nzv'),
tuneGrid   = grid,
na.action  = na.omit
)
#plot(modelo.knn)
knn.predict <- predict(modelo.knn, test_data)
test_data$pred <- knn.predict
ggplot(test_data, aes(x = knn.predict, y = Resultado_Final)) +
labs(title = "Modelo KNN - Obs vs Pred",
x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
#library(keras)
#UNCOMMENT TO INSTALL KERAS
#install_keras(method = c("auto", "virtualenv", "conda"), conda = "auto",
#  tensorflow = "default", extra_packages = NULL)
library(caret)
set.seed(500)
#Defininindo o particionamento dos dados
partition <- createDataPartition(y=data$Nome_do_Candidato, p=.8, list=FALSE)
fit_data  <- data[partition,]
test_data <- data[-partition,]
ctrl <- trainControl(method = "cv", number = 5, search = "random")
grid <- expand.grid(k = 1:50)
modelo.knn <- train(
Resultado_Final ~.,
data       = data,
method     = "knn",
trControl  = ctrl,
preProcess = c('nzv'),
tuneGrid   = grid,
na.action  = na.omit
)
plot(modelo.knn)
knn.predict <- predict(modelo.knn, test_data)
test_data$pred <- knn.predict
ggplot(test_data, aes(x = knn.predict, y = Resultado_Final)) +
labs(title = "Modelo KNN - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
set.seed(849)
modelo.hybrid.neural <- train(x = rec_reg,
data = training,
method = "HYFIS",
tuneLength = 2,
trControl = ctrl)
set.seed(849)
modelo.hybrid.neural <- train(
Resultado_Final ~.,
data       = data,
method     = "HYFIS",
tuneLength = 2,
trControl  = ctrl)
set.seed(849)
#Hybrid Neural Fuzzy Inference System
modelo.hybrid.neural <- train(
Resultado_Final ~.,
data       = data,
method     = "HYFIS",
tuneLength = 2,
trControl  = ctrl)
modelo.mars <- train(
Resultado_Final ~.,,
data = data,
method = "earth",
trControl = ctrl,
preProcess = c('nzv'),
tuneLength = 10,
na.action = na.omit)
modelo.mars <- train(
Resultado_Final ~.,
data = data,
method = "earth",
trControl = ctrl,
preProcess = c('nzv'),
tuneLength = 10,
na.action = na.omit)
plot(modelo.mars)
plot(varImp(modelo.mars))
grid <- expand.grid(k = 1:50)
modelo.knn <- train(
Resultado_Final ~.,
data       = data,
method     = "knn",
trControl  = ctrl,
preProcess = c('nzv'),
tuneGrid   = grid,
na.action  = na.omit
)
plot(modelo.knn)
knn.predict <- predict(modelo.knn, test_data)
test_data$pred <- knn.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo KNN - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
modelo.mars <- train(
Resultado_Final ~.,
data = data,
method = "earth",
trControl = ctrl,
preProcess = c('nzv'),
tuneLength = 10,
na.action = na.omit)
plot(modelo.mars)
mars.predict <- predict(modelo.mars, test_data)
test_data$pred <- mars.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo MARs - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
View(data)
install.packages("mlpSGD")
install.packages("mlpSGD", dependencies = TRUE)
install.packages("FCNN4R")
set.seed(666)
modelo.mars <- train(
Resultado_Final ~.,
data = data,
method = "mlpSGD",
trControl = ctrl,
preProcess = c('nzv'),
na.action = na.omit)
set.seed(666)
modelo.mars <- train(
Resultado_Final ~.,
data = data,
method = "mlpSGD",
trControl = ctrl,
preProcess = c('nzv'),
na.action = na.omit)
modelo.mars <- train(
Resultado_Final ~.,
data = data,
method = "earth",
trControl = ctrl,
preProcess = c('nzv'),
tuneLength = 10,
na.action = na.omit)
plot(modelo.mars)
mars.predict <- predict(modelo.mars, test_data)
test_data$pred <- mars.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo MARs - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
set.seed(666)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.mlp <- train(
Resultado_Final ~.,
data = data,
method = "mlpSGD",
trControl = ctrl,
preProcess = c('nzv'),
na.action = na.omit)
plot(modelo.mlp)
plot(modelo.mlp$bestTune)
plot(modelo.mlp$bestTune)
ggplot(modelo.mlp)
library(FCNN4R)
mlp_plot(modelo.mlp, show_weights = FALSE, show_neuron_idx = TRUE)
mlp_plot(modelo, show_weights = FALSE, show_neuron_idx = TRUE)
mlp_plot(modelo.mlp, show_weights = FALSE, show_neuron_idx = TRUE)
mlp_plot(modelo.mlp$bestTune, show_weights = FALSE, show_neuron_idx = TRUE)
mlp_plot(modelo.mlp$modelType)
mlp_plot(modelo.mlp$finalModel)
plot(modelo.mlp$finalModel)
mlp_plot(modelo.mlp$bestTune)
mlp_plot(modelo.mlp$pred)
mpl_net(data)
mlp_net(data)
net <- mlp_net(c(2, 6, 1))
mlp_plot(net)
# set activation function in all layers
net <- mlp_set_activation(net, layer = "a", "sigmoid")
# randomise weights
net <- mlp_rnd_weights(net)
# tolerance level
tol <- 0.5e-4
mlp_plot(net)
net <- mlp_net(c(8,3,6,1))
# set activation function in all layers
net <- mlp_set_activation(net, layer = "a", "sigmoid")
# randomise weights
net <- mlp_rnd_weights(net)
# tolerance level
tol <- 0.5e-4
mlp_plot(net)
inp <- c(fit_data$Resultado_da_Pesquisa,
fit_data$Indecisos,
fit_data$Brancos_Nulos)
netmse <- mlp_teach_rprop(net, inp, fit_data$Resultado_Final,
tol_level = tol,
max_epochs = 500, report_freq = 10)
inp <- c(fit_data$Resultado_da_Pesquisa,
fit_data$Indecisos,
fit_data$Brancos_Nulos)
inp
inp <- na.omit(c)
inp <- c(fit_data$Resultado_da_Pesquisa,
fit_data$Indecisos,
fit_data$Brancos_Nulos)
inp <- na.omit(inp)
netmse <- mlp_teach_rprop(net, inp, fit_data$Resultado_Final,
tol_level = tol,
max_epochs = 500, report_freq = 10)
inp
inp <- c(fit_data$Resultado_da_Pesquisa)
netmse <- mlp_teach_rprop(net, inp, fit_data$Resultado_Final,
tol_level = tol,
max_epochs = 500, report_freq = 10)
net <- mlp_net(c(3,3,6,1))
# set activation function in all layers
net <- mlp_set_activation(net, layer = "a", "sigmoid")
# randomise weights
net <- mlp_rnd_weights(net)
# tolerance level
tol <- 0.5e-4
inp <- c(fit_data$Resultado_da_Pesquisa,
fit_data$Indecisos,
fit_data$Brancos_Nulos)
netmse <- mlp_teach_rprop(net, inp, fit_data$Resultado_Final,
tol_level = tol,
max_epochs = 500, report_freq = 10)
dim(inp) <- c(length(fit_data$X1), 3)
netmse <- mlp_teach_rprop(net, inp, fit_data$Resultado_Final,
tol_level = tol,
max_epochs = 500, report_freq = 10)
out <- c(fit_data$Resultado_Final)
dim(out) <- (length(fit_data$X1),1)
dim(out) <- (length(fit_data$X1), 1)
dim(out) <- c(length(fit_data$X1), 1)
r
netmse <- mlp_teach_rprop(net, inp, out,
tol_level = tol,
max_epochs = 500, report_freq = 10)
mlp_plot(net)
mlp_plot(net)
mlp_plot(netmse)
mlp_plot(netmse)
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.mlp <- train(
Resultado_Final ~.,
data = data,
method = "mlpSGD",
trControl = ctrl,
preProcess = c('nzv'),
na.action = na.omit)
plot(modelo.mlp, TYPE= 1)
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.mlp <- train(
Resultado_Final ~.,
data       = data,
method     = "mlpSGD",
trControl  = ctrl,
preProcess = c('nzv'),
repeats    = 5,
na.action  = na.omit)
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.mlp <- train(
Resultado_Final ~.,
data       = data,
method     = "mlpSGD",
trControl  = ctrl,
preProcess = c('nzv'),
repeats    = 5,
na.action  = na.omit)
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.mlp <- train(
Resultado_Final ~.,
data       = data,
method     = "mlpSGD",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
ggplot(modelo.mlp)
ggplot(modelo.mlp)
ggplot(modelo.mlp)
mlp.predict <- predict(modelo.mlp, test_data)
test_data$pred <- mpl.predict
test_data$pred <- mlp.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo mplSGD - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "mxnet",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "mxnet",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "mxnetAdam",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "neuralnet",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "neuralnet",
trControl  = ctrl,
na.action  = na.omit)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "neuralnet",
na.action  = na.omit)
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "nnet",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
ggplot(modelo.net)
net.predict <- predict(modelo.mlp, test_data)
test_data$pred <- mlp.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo mplSGD - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
set.seed(13)
#Multilayer Perceptron Network by Stochastic Gradient Descen
modelo.net <- train(
Resultado_Final ~.,
data       = data,
method     = "nnet",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
ggplot(modelo.net)
ggplot(modelo.net$bestTune)
ggplot(modelo.net$finalModel)
plot(modelo.net)
net.predict <- predict(modelo.net, test_data)
test_data$pred <- net.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo mplSGD - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
#eXtreme Gradient Boosting
modelo.egb <- train(
Resultado_Final ~.,
data       = data,
method     = "xgbDART",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
plot(modelo.egb)
ggplot(modelo.egb)
egb.predict <- predict(modelo.egb, test_data)
test_data$pred <- egb.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo mplSGD - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo eXtreme Gradient Boosting - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo Neural Network - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
set.seed(127)
#eXtreme Gradient Boosting
modelo.egb <- train(
Resultado_Final ~.,
data       = data,
method     = "ANFIS",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
set.seed(127)
#eXtreme Gradient Boosting
modelo.egb <- train(
Resultado_Final ~.,
data       = data,
method     = "cubist",
trControl  = ctrl,
preProcess = c('nzv'),
na.action  = na.omit)
egb.predict <- predict(modelo.egb, test_data)
test_data$pred <- egb.predict
ggplot(test_data, aes(x = pred, y = Resultado_Final)) +
labs(title = "Modelo eXtreme Gradient Boosting - Obs vs Pred", x = "Predição", y = "Observado")+
geom_jitter(colour = "red") +
geom_abline(colour = "blue")
